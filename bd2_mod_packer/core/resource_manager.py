#!/usr/bin/env python3
"""
BD2èµ„æºæ›¿æ¢ä¸»æ§åˆ¶å™¨

BD2æ¸¸æˆèµ„æºæ›¿æ¢è‡ªåŠ¨åŒ–æµç¨‹æ§åˆ¶å™¨ï¼ŒåŒ…æ‹¬ï¼š
- ç‰ˆæœ¬æ£€æµ‹å’Œæ›´æ–°
- æ›¿æ¢æ–‡ä»¶å˜æ›´è¿½è¸ª
- èµ„æºä¸‹è½½å’Œæ›¿æ¢

ä½œè€…: OLDNEW
æ—¥æœŸ: 2025-08-14
"""

import json
import logging
import os
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from ..config.settings import BD2Config
from ..api import BD2CDNAPI
from .data_downloader import BD2DataDownloader
from .unity_processor import UnityResourceProcessor
from ..api import CharacterScraper

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class ReplaceTask:
    """æ›¿æ¢ä»»åŠ¡ä¿¡æ¯"""
    type: str  # IDLEæˆ–CUTSCENE
    replace_dir: str
    data_name: str
    downloaded_dir: str
    target_dir: str
    mod_name: str = ""
    idle_or_cutscene_value: str = ""
    hash_id: str = ""
    char_id: str = ""  # è§’è‰²IDï¼Œä»modæ–‡ä»¶åè·å–
    should_execute: bool = True  # æ˜¯å¦éœ€è¦æ‰§è¡Œè¯¥ä»»åŠ¡
    


@dataclass
class ReplaceEntry:
    """æ›¿æ¢ç›®å½•æ¡ç›®"""
    path: str
    mtime: float
    subfile: List[Dict[str, Any]]


@dataclass
class UpdateSummary:
    """æ›´æ–°æ‘˜è¦"""
    version_changed: bool = False
    old_version: Optional[int] = None
    new_version: Optional[int] = None
    replace_dirs_to_update: List[str] = None
    total_replace_dirs: int = 0
    
    def __post_init__(self):
        if self.replace_dirs_to_update is None:
            self.replace_dirs_to_update = []


class BD2ResourceManager:
    """BD2èµ„æºç®¡ç†å™¨ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, project_root: str = None, proxies : Optional[Dict[str, str]] = None, replace_dir: str = "replace"):
        """
        åˆå§‹åŒ–BD2èµ„æºç®¡ç†å™¨
        
        å‚æ•°:
            project_root: é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰è„šæœ¬çš„ä¸Šçº§ç›®å½•
            proxies: ä»£ç†è®¾ç½®
            replace_dir: æ›¿æ¢ç›®å½•åç§°ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸º"replace"
        """
        # åˆå§‹åŒ–é…ç½®ç³»ç»Ÿ
        self.config = BD2Config()
        
        if project_root is None:
            # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆmain_v2.pyçš„ä¸Šçº§ç›®å½•ï¼‰
            current_file = Path(__file__).resolve()
            self.project_root = current_file.parent.parent.parent
        else:
            self.project_root = Path(project_root)
        
        self.data_json_path = self.project_root / "data.json"
        # ä½¿ç”¨workspaceè·¯å¾„
        self.replace_dir = self.config.get_mod_workspace_path(replace_dir)
        self.replace_dir_name = replace_dir  # ä¿å­˜ç›®å½•åç§°ç”¨äºdata.jsoné”®å€¼
        self.downloaded_dir = self.config.get_sourcedata_dir()
        self.target_dir = self.config.get_targetdata_dir() / replace_dir  # ä¸ºæ¯ä¸ªä½œè€…åˆ›å»ºç‹¬ç«‹çš„targetå­ç›®å½•
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.cdn_api = BD2CDNAPI(proxies=proxies)
        self.character_scraper = CharacterScraper()
        self.unity_processor = UnityResourceProcessor()
        self.data_downloader = BD2DataDownloader(output_dir=str(self.downloaded_dir),proxies=proxies)
        
        logger.info(f"BD2èµ„æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œé¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        logger.info(f"ä½¿ç”¨æ›¿æ¢ç›®å½•: {self.replace_dir} (é”®å€¼: {self.replace_dir_name})")
    
    def _load_data_json(self) -> Dict[str, Any]:
        """
        åŠ è½½data.jsonæ–‡ä»¶
        
        è¿”å›:
            Dict[str, Any]: data.jsonå†…å®¹ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨è¿”å›é»˜è®¤ç»“æ„
        """
        if not self.data_json_path.exists():
            logger.info("data.jsonä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºé»˜è®¤é…ç½®")
            return {
                "authors": {}  # æ”¹ä¸ºæŒ‰ä½œè€…åˆ†ç»„çš„ç»“æ„ï¼Œç§»é™¤å…¨å±€ç‰ˆæœ¬ä¿¡æ¯
            }
        
        try:
            with open(self.data_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # å…¼å®¹æ—§æ ¼å¼ï¼šå¦‚æœå‘ç°æ—§çš„replaceDirå­—æ®µï¼Œè¿›è¡Œè¿ç§»
                if "replaceDir" in data and "authors" not in data:
                    logger.info("æ£€æµ‹åˆ°æ—§æ ¼å¼data.jsonï¼Œæ­£åœ¨è¿ç§»åˆ°æ–°æ ¼å¼...")
                    old_replace_dirs = data.pop("replaceDir", [])
                    old_version = data.pop("version", 0)
                    old_update_time = data.pop("updateTime", 0)
                    data["authors"] = {
                        "replace": {
                            "version": old_version,
                            "updateTime": old_update_time,
                            "dirs": old_replace_dirs
                        }
                    }
                    # ä¿å­˜è¿ç§»åçš„æ•°æ®
                    self._save_data_json(data)
                    logger.info("data.jsonæ ¼å¼è¿ç§»å®Œæˆ")
                elif "authors" not in data:
                    data["authors"] = {}
                
                # è¿ç§»æ—§çš„authorsæ ¼å¼ï¼ˆæ•°ç»„æ ¼å¼ï¼‰åˆ°æ–°æ ¼å¼ï¼ˆå¯¹è±¡æ ¼å¼ï¼‰
                authors_data = data.get("authors", {})
                migration_needed = False
                for author_name, author_data in list(authors_data.items()):
                    if isinstance(author_data, list):  # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯ç›®å½•æ•°ç»„
                        logger.info(f"è¿ç§»ä½œè€…'{author_name}'æ•°æ®åˆ°æ–°æ ¼å¼...")
                        old_version = data.get("version", 0)
                        old_update_time = data.get("updateTime", 0)
                        authors_data[author_name] = {
                            "version": old_version,
                            "updateTime": old_update_time,
                            "dirs": author_data
                        }
                        migration_needed = True
                
                if migration_needed:
                    # æ¸…ç†å…¨å±€ç‰ˆæœ¬ä¿¡æ¯
                    data.pop("version", None)
                    data.pop("updateTime", None)
                    data["authors"] = authors_data
                    self._save_data_json(data)
                    logger.info("ä½œè€…æ•°æ®æ ¼å¼è¿ç§»å®Œæˆ")
                
                # è·å–å½“å‰ä½œè€…çš„ç‰ˆæœ¬ä¿¡æ¯
                current_author = authors_data.get(self.replace_dir_name, {})
                current_version = current_author.get("version", 0)
                logger.info(f"æˆåŠŸåŠ è½½data.jsonï¼Œä½œè€…'{self.replace_dir_name}'å½“å‰ç‰ˆæœ¬: {current_version}")
                return data
        except Exception as e:
            logger.error(f"åŠ è½½data.jsonå¤±è´¥: {e}")
            logger.info("ä½¿ç”¨é»˜è®¤é…ç½®")
            return {
                "authors": {}
            }
    
    def _save_data_json(self, data: Dict[str, Any]) -> None:
        """
        ä¿å­˜data.jsonæ–‡ä»¶
        
        å‚æ•°:
            data: è¦ä¿å­˜çš„æ•°æ®
        """
        try:
            with open(self.data_json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=4, ensure_ascii=False)
            # è·å–å½“å‰ä½œè€…çš„ç‰ˆæœ¬ä¿¡æ¯ç”¨äºæ—¥å¿—
            current_author = data.get("authors", {}).get(self.replace_dir_name, {})
            current_version = current_author.get("version", 0)
            logger.info(f"æˆåŠŸä¿å­˜data.jsonï¼Œä½œè€…'{self.replace_dir_name}'ç‰ˆæœ¬: {current_version}")
        except Exception as e:
            logger.error(f"ä¿å­˜data.jsonå¤±è´¥: {e}")
            raise
    
    def _get_directory_mtime(self, dir_path: Path) -> float:
        """
        è·å–ç›®å½•çš„æœ€åä¿®æ”¹æ—¶é—´ï¼ˆå–ç›®å½•å†…æ‰€æœ‰æ–‡ä»¶çš„æœ€æ–°ä¿®æ”¹æ—¶é—´ï¼‰
        
        å‚æ•°:
            dir_path: ç›®å½•è·¯å¾„
            
        è¿”å›:
            float: æœ€åä¿®æ”¹æ—¶é—´æˆ³
        """
        if not dir_path.exists():
            return 0.0
        
        max_mtime = dir_path.stat().st_mtime
        
        try:
            for item in dir_path.rglob('*'):
                if item.is_file():
                    max_mtime = max(max_mtime, item.stat().st_mtime)
        except Exception as e:
            logger.warning(f"è·å–ç›®å½•ä¿®æ”¹æ—¶é—´å¤±è´¥ {dir_path}: {e}")
        
        return max_mtime
    
    def _get_subfiles_info(self, dir_path: Path) -> List[Dict[str, Any]]:
        """
        è·å–ç›®å½•ä¸‹æ‰€æœ‰å­æ–‡ä»¶çš„ä¿¡æ¯
        
        å‚æ•°:
            dir_path: ç›®å½•è·¯å¾„
            
        è¿”å›:
            List[Dict]: å­æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        """
        subfiles = []
        if not dir_path.exists():
            return subfiles
        
        try:
            for item in dir_path.iterdir():
                if item.is_file():
                    subfiles.append({
                        "path": str(item),
                        "mtime": item.stat().st_mtime
                    })
                elif item.is_dir():
                    # é€’å½’å¤„ç†å­ç›®å½•
                    subfiles.append({
                        "path": str(item),
                        "mtime": self._get_directory_mtime(item)
                    })
        except Exception as e:
            logger.warning(f"è·å–å­æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {dir_path}: {e}")
        
        return subfiles
    
    def _scan_replace_directories(self) -> List[str]:
        """
        æ‰«æreplaceç›®å½•ä¸‹çš„æ‰€æœ‰MODç›®å½•
        
        æ–°ç›®å½•ç»“æ„: workspace/mod_projects/ä½œè€…å/IDLEæˆ–CUTSCENE/MODåç§°/
        
        è¿”å›:
            List[str]: MODç›®å½•è·¯å¾„åˆ—è¡¨
        """
        replace_dirs = []
        
        if not self.replace_dir.exists():
            logger.warning(f"replaceç›®å½•ä¸å­˜åœ¨: {self.replace_dir}")
            return replace_dirs
        
        try:
            # éå†ä½œè€…ç›®å½•
            
                
                # åœ¨ä½œè€…ç›®å½•ä¸‹æŸ¥æ‰¾IDLEå’ŒCUTSCENEç›®å½•
            for animation_type_dir in self.replace_dir.iterdir():
                if (animation_type_dir.is_dir() and 
                    animation_type_dir.name in ["IDLE", "CUTSCENE"]):
                    # éå†MODç›®å½•
                    for mod_dir in animation_type_dir.iterdir():
                        if mod_dir.is_dir():
                            relative_path = mod_dir.relative_to(self.project_root)
                            replace_dirs.append(str(relative_path))
            
            logger.info(f"æ‰«æåˆ° {len(replace_dirs)} ä¸ªæ›¿æ¢ç›®å½•")
            return replace_dirs
            
        except Exception as e:
            logger.error(f"æ‰«æreplaceç›®å½•å¤±è´¥: {e}")
            return replace_dirs
    
    def _is_directory_empty(self, dir_path: Path) -> bool:
        """
        æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©ºï¼ˆæ²¡æœ‰ä»»ä½•æ–‡ä»¶ï¼Œåªæœ‰ç©ºæ–‡ä»¶å¤¹ï¼‰
        
        å‚æ•°:
            dir_path: ç›®å½•è·¯å¾„
            
        è¿”å›:
            bool: å¦‚æœç›®å½•ä¸ºç©ºè¿”å›True
        """
        if not dir_path.exists():
            return True
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ–‡ä»¶
            for item in dir_path.rglob('*'):
                if item.is_file():
                    # logger.info(f"ç›®å½•ä¸ä¸ºç©º: {dir_path}")
                    return False
            # logger.info(f"ç›®å½•ä¸ºç©º: {dir_path}")
            return True
        except Exception as e:
            logger.warning(f"æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©ºå¤±è´¥ {dir_path}: {e}")
            return True
    
    def check_version_and_updates(self) -> Tuple[bool, UpdateSummary]:
        """
        æ£€æµ‹æ¸¸æˆç‰ˆæœ¬å’Œæ›¿æ¢æ–‡ä»¶æ›´æ–°
        
        è¿”å›:
            Tuple[bool, UpdateSummary]: (æ˜¯å¦éœ€è¦æ›´æ–°, æ›´æ–°æ‘˜è¦)
        """
        logger.info("å¼€å§‹æ£€æµ‹ç‰ˆæœ¬å’Œæ–‡ä»¶æ›´æ–°...")
        
        # åŠ è½½å½“å‰é…ç½®
        data = self._load_data_json()
        
        # è·å–å½“å‰ä½œè€…çš„æ•°æ®
        authors_data = data.get("authors", {})
        current_author_data = authors_data.get(self.replace_dir_name, {})
        current_version = current_author_data.get("version", 0)
        current_update_time = current_author_data.get("updateTime", 0)
        
        # åˆ›å»ºæ›´æ–°æ‘˜è¦
        summary = UpdateSummary()
        summary.old_version = current_version
        
        needs_update = False
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šæ£€æµ‹æ¸¸æˆç‰ˆæœ¬
            logger.info("æ£€æµ‹æ¸¸æˆç‰ˆæœ¬...")
            server_info = self.cdn_api.get_version_info()
            server_version = int(server_info.version)  # BD2VersionInfo.version
            server_update_time = int(server_info.version)  # ä½¿ç”¨ç‰ˆæœ¬å·ä½œä¸ºæ›´æ–°æ—¶é—´
            
            summary.new_version = server_version
            
            if server_version != current_version or server_update_time != current_update_time:
                logger.info(f"ä½œè€…'{self.replace_dir_name}'æ¸¸æˆç‰ˆæœ¬æœ‰æ›´æ–°: {current_version} -> {server_version}")
                summary.version_changed = True
                needs_update = True
                
                # æ›´æ–°å½“å‰ä½œè€…çš„ç‰ˆæœ¬ä¿¡æ¯
                if self.replace_dir_name not in authors_data:
                    authors_data[self.replace_dir_name] = {}
                authors_data[self.replace_dir_name]["version"] = server_version
                authors_data[self.replace_dir_name]["updateTime"] = server_update_time
                
                # ä¿æŒç°æœ‰çš„dirsæ•°æ®
                if "dirs" not in authors_data[self.replace_dir_name]:
                    authors_data[self.replace_dir_name]["dirs"] = []
                
                data["authors"] = authors_data
                self._save_data_json(data)
            else:
                logger.info(f"ä½œè€…'{self.replace_dir_name}'æ¸¸æˆç‰ˆæœ¬æ— å˜åŒ–")
            
            # ç¬¬äºŒæ­¥ï¼šå»ºç«‹replace_updateæ¸…å•
            logger.info("æ£€æµ‹æ›¿æ¢æ–‡ä»¶æ›´æ–°...")
            current_replace_dirs = self._scan_replace_directories()
            summary.total_replace_dirs = len(current_replace_dirs)
            
            # è·å–å½“å‰ä½œè€…çš„ç›®å½•æ•°æ®
            current_author_dirs = current_author_data.get("dirs", [])
            
            # æ„å»ºç°æœ‰replaceDiræ˜ å°„
            existing_replace_map = {}
            for entry in current_author_dirs:
                # å°†ç»å¯¹è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„è¿›è¡Œæ¯”è¾ƒ
                rel_path = Path(entry["path"]).relative_to(self.project_root)
                existing_replace_map[str(rel_path)] = entry
            
            updated_replace_dirs = []
            dirs_to_update = []
            
            # æ£€æŸ¥æ¯ä¸ªæ›¿æ¢ç›®å½•
            for replace_dir_rel in current_replace_dirs:
                replace_dir_path = self.project_root / replace_dir_rel
                current_mtime = self._get_directory_mtime(replace_dir_path)
                current_subfiles = self._get_subfiles_info(replace_dir_path)
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if replace_dir_rel in existing_replace_map:
                    existing_entry = existing_replace_map[replace_dir_rel]
                    existing_mtime = existing_entry.get("mtime", 0)
                    existing_subfiles = existing_entry.get("subfile", [])
                    
                    # æ¯”è¾ƒç›®å½•ä¿®æ”¹æ—¶é—´
                    if abs(current_mtime - existing_mtime) > 1:  # å…è®¸1ç§’è¯¯å·®
                        logger.info(f"ç›®å½•å·²æ›´æ–°: {replace_dir_rel}")
                        dirs_to_update.append(replace_dir_rel)
                        needs_update = True
                    else:
                        # æ¯”è¾ƒå­æ–‡ä»¶
                        subfiles_changed = False
                        existing_subfile_map = {sf["path"]: sf["mtime"] for sf in existing_subfiles}
                        
                        for subfile in current_subfiles:
                            subfile_path = subfile["path"]
                            subfile_mtime = subfile["mtime"]
                            
                            if (subfile_path not in existing_subfile_map or 
                                abs(subfile_mtime - existing_subfile_map[subfile_path]) > 1):
                                subfiles_changed = True
                                break
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å­æ–‡ä»¶è¢«åˆ é™¤
                        current_subfile_paths = {sf["path"] for sf in current_subfiles}
                        for existing_subfile_path in existing_subfile_map:
                            if existing_subfile_path not in current_subfile_paths:
                                subfiles_changed = True
                                break
                        
                        if subfiles_changed:
                            logger.info(f"å­æ–‡ä»¶å·²æ›´æ–°: {replace_dir_rel}")
                            dirs_to_update.append(replace_dir_rel)
                            needs_update = True
                
                else:
                    # æ–°å¢çš„ç›®å½•
                    logger.info(f"å‘ç°æ–°ç›®å½•: {replace_dir_rel}")
                    dirs_to_update.append(replace_dir_rel)
                    needs_update = True
                
                # æ›´æ–°æ¡ç›®
                updated_replace_dirs.append({
                    "path": str(replace_dir_path),
                    "mtime": current_mtime,
                    "subfile": current_subfiles
                })
            
            # æ£€æŸ¥å·²åˆ é™¤çš„ç›®å½•ï¼ˆåªæ£€æŸ¥å½“å‰ä½œè€…çš„ç›®å½•ï¼‰
            for existing_rel_path in existing_replace_map:
                if existing_rel_path not in current_replace_dirs:
                    logger.info(f"ç›®å½•å·²åˆ é™¤: {existing_rel_path}")
                    needs_update = True
            
            # æ›´æ–°data.jsonä¸­çš„å½“å‰ä½œè€…æ•°æ®
            if needs_update:
                # ç¡®ä¿å½“å‰ä½œè€…çš„æ•°æ®ç»“æ„æ­£ç¡®
                if self.replace_dir_name not in authors_data:
                    authors_data[self.replace_dir_name] = {
                        "version": current_version,
                        "updateTime": current_update_time,
                        "dirs": []
                    }
                
                # æ›´æ–°ç›®å½•ä¿¡æ¯ï¼Œä¿æŒç‰ˆæœ¬ä¿¡æ¯
                authors_data[self.replace_dir_name]["dirs"] = updated_replace_dirs
                data["authors"] = authors_data
                self._save_data_json(data)
            
            summary.replace_dirs_to_update = dirs_to_update
            
            logger.info(f"æ£€æµ‹å®Œæˆ: éœ€è¦æ›´æ–°={needs_update}, ç‰ˆæœ¬å˜åŒ–={summary.version_changed}, ç›®å½•æ›´æ–°æ•°={len(dirs_to_update)}")
            
            return needs_update, summary
            
        except Exception as e:
            logger.error(f"æ£€æµ‹ç‰ˆæœ¬å’Œæ›´æ–°å¤±è´¥: {e}")
            return True, summary  # å‡ºé”™æ—¶è¿”å›éœ€è¦æ›´æ–°
    
    def _build_replace_mapping(self, specific_dirs: List[str] = None) -> List[ReplaceTask]:
        """
        å»ºç«‹æ›¿æ¢æ˜ å°„æ¸…å•
        
        æ–°ç›®å½•ç»“æ„: workspace/mod_projects/ä½œè€…å/IDLEæˆ–CUTSCENE/MODåç§°/
        
        å‚æ•°:
            specific_dirs: æŒ‡å®šè¦å¤„ç†çš„ç›®å½•åˆ—è¡¨ï¼ˆå¢é‡æ›´æ–°æ—¶ä½¿ç”¨ï¼‰ï¼Œä¸ºNoneæ—¶å¤„ç†æ‰€æœ‰ç›®å½•
            
        è¿”å›:
            List[ReplaceTask]: æ›¿æ¢ä»»åŠ¡åˆ—è¡¨
        """
        if specific_dirs:
            logger.info(f"å¼€å§‹å»ºç«‹å¢é‡æ›¿æ¢æ˜ å°„æ¸…å•ï¼Œå¤„ç† {len(specific_dirs)} ä¸ªç›®å½•...")
        else:
            logger.info("å¼€å§‹å»ºç«‹å®Œæ•´æ›¿æ¢æ˜ å°„æ¸…å•...")
        
        replace_tasks = []
        
        if not self.replace_dir.exists():
            logger.warning(f"replaceç›®å½•ä¸å­˜åœ¨: {self.replace_dir}")
            return replace_tasks
        
        try:
            # è½¬æ¢specific_dirsä¸ºç›¸å¯¹è·¯å¾„çš„é›†åˆä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾
            specific_dirs_set = set()
            if specific_dirs:
                for dir_path in specific_dirs:
                    specific_dirs_set.add(dir_path.replace("\\", "/"))
            
            # æ–°ç›®å½•ç»“æ„ï¼šéå† ä½œè€…ç›®å½• -> IDLE/CUTSCENEç›®å½• -> MODç›®å½•
            
                
            logger.info(f"å¤„ç†ä½œè€…ç›®å½•: {self.replace_dir.name}")
            
            # åœ¨ä½œè€…ç›®å½•ä¸‹æŸ¥æ‰¾IDLEå’ŒCUTSCENEç›®å½•
            for animation_type_dir in self.replace_dir.iterdir():
                if not animation_type_dir.is_dir():
                    continue
                
                # åªå¤„ç†IDLEå’ŒCUTSCENEç›®å½•
                if animation_type_dir.name not in ["IDLE", "CUTSCENE"]:
                    continue
                
                type_name = animation_type_dir.name
                logger.info(f"  å¤„ç†åŠ¨ç”»ç±»å‹: {type_name}")
                
                # éå†MODç›®å½•
                for mod_dir in animation_type_dir.iterdir():
                    if not mod_dir.is_dir():
                        continue
                    
                    mod_name = mod_dir.name
                    logger.info(f"    å¤„ç†MOD: {mod_name}")
                    
                    # æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º
                    if self._is_directory_empty(mod_dir):
                        logger.info(f"    è·³è¿‡ç©ºç›®å½•: {type_name}/{mod_name}")
                        continue
                    # logger.info(f"    å¼€å§‹åˆ›å»ºæ›¿æ¢ä»»åŠ¡======================================")
                    # ç¡®å®šä»»åŠ¡æ˜¯å¦åº”è¯¥æ‰§è¡Œ
                    should_execute = True
                    if specific_dirs:
                        # æ„å»ºå½“å‰ç›®å½•çš„ç›¸å¯¹è·¯å¾„
                        current_dir_rel = mod_dir.relative_to(self.project_root)
                        current_dir_rel_str = str(current_dir_rel).replace("\\", "/")
                        should_execute = current_dir_rel_str in specific_dirs_set
                        if should_execute:
                            logger.info(f"    âœ“ ç›®å½•åœ¨æ›´æ–°åˆ—è¡¨ä¸­: {type_name}/{mod_name}")
                        else:
                            logger.info(f"    - ç›®å½•ä¸åœ¨æ›´æ–°åˆ—è¡¨ä¸­: {type_name}/{mod_name}")
                    
                    task = self._create_replace_task(type_name, mod_dir, should_execute)
                    # logger.info(f"    åˆ›å»ºæ›¿æ¢ä»»åŠ¡: {task}")
                    if task:
                        replace_tasks.append(task)
            
            # å¦‚æœæ˜¯å¢é‡æ›´æ–°ï¼Œéœ€è¦é¢å¤–å¤„ç†ç›¸åŒç›®æ ‡è·¯å¾„çš„ä»»åŠ¡
            if specific_dirs:
                # æ”¶é›†æ‰€æœ‰å¯æ‰§è¡Œä»»åŠ¡çš„ç›®æ ‡è·¯å¾„
                executable_target_dirs = set()
                for task in replace_tasks:
                    if task.should_execute:
                        executable_target_dirs.add(task.target_dir)
                
                # æ ‡è®°å…·æœ‰ç›¸åŒç›®æ ‡è·¯å¾„çš„å…¶ä»–ä»»åŠ¡ä¸ºå¯æ‰§è¡Œ
                additional_count = 0
                for task in replace_tasks:
                    if not task.should_execute and task.target_dir in executable_target_dirs:
                        task.should_execute = True
                        additional_count += 1
                        logger.info(f"    âœ“ ç›¸åŒç›®æ ‡è·¯å¾„ï¼Œæ ‡è®°ä¸ºå¯æ‰§è¡Œ: {task.type}/{task.mod_name}")
                
                if additional_count > 0:
                    logger.info(f"å› ç›¸åŒç›®æ ‡è·¯å¾„é¢å¤–æ ‡è®° {additional_count} ä¸ªä»»åŠ¡ä¸ºå¯æ‰§è¡Œ")
            
            # ç»Ÿè®¡ä»»åŠ¡æ•°é‡
            execute_count = sum(1 for task in replace_tasks if task.should_execute)
            total_count = len(replace_tasks)
            logger.info(f"æ›¿æ¢æ˜ å°„æ¸…å•å»ºç«‹å®Œæˆï¼Œå…± {total_count} ä¸ªä»»åŠ¡ï¼Œå…¶ä¸­ {execute_count} ä¸ªéœ€è¦æ‰§è¡Œ")

            return replace_tasks
            
        except Exception as e:
            logger.error(f"å»ºç«‹æ›¿æ¢æ˜ å°„æ¸…å•å¤±è´¥: {e}")
            return replace_tasks
    
    def _create_replace_task(self, type_name: str, mod_dir: Path, should_execute: bool = True) -> Optional[ReplaceTask]:
        # logger.info(f"    åˆ›å»ºæ›¿æ¢ä»»åŠ¡: {type_name}/{mod_dir.name}/ {should_execute}")
        """
        ä¸ºå•ä¸ªMODç›®å½•åˆ›å»ºæ›¿æ¢ä»»åŠ¡
        
        æ–°é€»è¾‘:
        1. ä»MODç›®å½•è·¯å¾„åˆ¤æ–­IDLE/CUTSCENEç±»å‹
        2. ä»modæ–‡ä»¶åæå–è§’è‰²ID
        3. ä½¿ç”¨IDæŸ¥æ‰¾æ–¹æ³•è·å–idle/cutsceneå€¼
        
        å‚æ•°:
            type_name: ç±»å‹å(IDLE/CUTSCENE)ï¼Œä»ç›®å½•è·¯å¾„è·å–
            mod_dir: MODç›®å½•è·¯å¾„
            should_execute: æ˜¯å¦éœ€è¦æ‰§è¡Œè¯¥ä»»åŠ¡
            
        è¿”å›:
            Optional[ReplaceTask]: åˆ›å»ºçš„ä»»åŠ¡ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            mod_name = mod_dir.name
            
            # æ­¥éª¤1ï¼šä»modæ–‡ä»¶ä¸­è·å–è§’è‰²ID
            char_id = self._extract_char_id_from_mod_files(mod_dir)
            if not char_id:
                logger.warning(f"    æ— æ³•ä»MODæ–‡ä»¶ä¸­æå–è§’è‰²IDï¼Œè·³è¿‡: {type_name}/{mod_name}")
                return None
            
            logger.info(f"    æå–åˆ°è§’è‰²ID: {char_id}")
            
            # æ­¥éª¤2ï¼šä½¿ç”¨IDæŸ¥æ‰¾æ–¹æ³•è·å–idleæˆ–cutsceneå€¼
            try:
                if type_name.upper() == "IDLE":
                    idle_or_cutscene_value = self.character_scraper.get_idle_by_id(char_id)
                elif type_name.upper() == "CUTSCENE":
                    idle_or_cutscene_value = self.character_scraper.get_cutscene_by_id(char_id)
                else:
                    logger.warning(f"    æœªçŸ¥ç±»å‹: {type_name}ï¼Œè·³è¿‡")
                    return None
            except Exception as e:
                logger.warning(f"    æ— æ³•è·å– {char_id} çš„{type_name}å€¼: {e}")
                return None
            
            if not idle_or_cutscene_value:
                logger.warning(f"    è§’è‰²ID {char_id} çš„{type_name}å€¼ä¸ºç©ºï¼Œè·³è¿‡")
                return None
            
            logger.info(f"    è·å–åˆ°{type_name}å€¼: {idle_or_cutscene_value}")
            
            # æ­¥éª¤3ï¼šé€šè¿‡BD2CDNAPIè·å–èµ„æºåç§°å’Œhash
            result = self.cdn_api.get_resource_bundle_name_and_hash(idle_or_cutscene_value)
            if not result:
                logger.warning(f"    æ— æ³•è·å– {idle_or_cutscene_value} çš„èµ„æºä¿¡æ¯ï¼Œè·³è¿‡")
                return None
            
            resource_name, hash_id = result
            logger.info(f"    èµ„æºåç§°: {resource_name}, Hash: {hash_id}")
            
            # æ­¥éª¤4ï¼šæ„å»ºè·¯å¾„
            replace_dir_path = str(mod_dir)
            downloaded_dir = f"{self.downloaded_dir}{os.sep}{resource_name}"
            target_dir = f"{self.target_dir}/{idle_or_cutscene_value}/{hash_id}/__data"
            
            # æ­¥éª¤5ï¼šåˆ›å»ºæ›¿æ¢ä»»åŠ¡
            task = ReplaceTask(
                type=type_name,
                replace_dir=replace_dir_path,
                data_name=resource_name,
                downloaded_dir=downloaded_dir,
                target_dir=target_dir,
                mod_name=mod_name,
                idle_or_cutscene_value=idle_or_cutscene_value,
                hash_id=hash_id,
                char_id=char_id,
                should_execute=should_execute
            )
            
            status_text = "âœ… æ·»åŠ æ›¿æ¢ä»»åŠ¡" if should_execute else "ğŸ“‹ æ·»åŠ ä»»åŠ¡(ä¸æ‰§è¡Œ)"
            logger.info(f"    {status_text}: {type_name}/{mod_name} (ID: {char_id})")
            return task
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ›¿æ¢ä»»åŠ¡å¤±è´¥ {type_name}/{mod_dir.name}: {e}")
            return None
    
    def _extract_char_id_from_mod_files(self, mod_dir: Path) -> Optional[str]:
        """
        ä»MODç›®å½•ä¸­çš„æ–‡ä»¶åæå–è§’è‰²ID
        
        æŸ¥æ‰¾è§„åˆ™ï¼š
        1. æŸ¥æ‰¾åç¼€ä¸º .atlas, .modfile, .skel, .json çš„æ–‡ä»¶
        2. æå–æ–‡ä»¶åï¼ˆä¸å«åç¼€ï¼‰ä½œä¸ºè§’è‰²ID
        3. ç§»é™¤å¯èƒ½å­˜åœ¨çš„ cutscene_ æˆ– idle_ å‰ç¼€
        4. å¦‚æœæ‰¾åˆ°å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„ID
        
        å‚æ•°:
            mod_dir: MODç›®å½•è·¯å¾„
            
        è¿”å›:
            Optional[str]: æå–åˆ°çš„è§’è‰²IDï¼ˆå·²ç§»é™¤å‰ç¼€ï¼‰ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            # æ”¯æŒçš„æ–‡ä»¶åç¼€
            supported_extensions = ['.atlas', '.modfile', '.skel', '.json']
            
            # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
            found_files = []
            for file_path in mod_dir.iterdir():
                if file_path.is_file():
                    file_ext = file_path.suffix.lower()
                    if file_ext in supported_extensions:
                        found_files.append(file_path)
            
            if not found_files:
                logger.warning(f"    ç›®å½•ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„modæ–‡ä»¶ (.atlas, .modfile, .skel, .json): {mod_dir}")
                return None
            
            # æå–æ‰€æœ‰æ–‡ä»¶çš„IDï¼ˆä¸å«åç¼€çš„æ–‡ä»¶åï¼‰
            char_ids = []
            for file_path in found_files:
                char_id = file_path.stem  # è·å–ä¸å«åç¼€çš„æ–‡ä»¶å
                
                # ç§»é™¤å¯èƒ½çš„å‰ç¼€
                if char_id:
                    original_id = char_id
                    # ç§»é™¤å¸¸è§çš„æ–‡ä»¶å‰ç¼€
                    if char_id.startswith('cutscene_'):
                        char_id = char_id[9:]  # ç§»é™¤ 'cutscene_' å‰ç¼€ï¼ˆ9ä¸ªå­—ç¬¦ï¼‰
                        logger.info(f"    ç§»é™¤cutscene_å‰ç¼€ï¼Œè§’è‰²ID: {char_id}")
                    elif char_id.startswith('idle_'):
                        char_id = char_id[5:]  # ç§»é™¤ 'idle_' å‰ç¼€ï¼ˆ5ä¸ªå­—ç¬¦ï¼‰
                        logger.info(f"    ç§»é™¤idle_å‰ç¼€ï¼Œè§’è‰²ID: {char_id}")
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è§’è‰²IDï¼ˆä½¿ç”¨é…ç½®çš„å‰ç¼€ï¼‰
                    if not self.config.is_valid_character_id_prefix(char_id):
                        logger.warning(f"    æå–çš„ID '{char_id}' ä¸åŒ¹é…ä»»ä½•å·²çŸ¥å‰ç¼€ï¼ŒåŸå§‹æ–‡ä»¶å: {original_id}")
                
                if char_id and char_id not in char_ids:
                    char_ids.append(char_id)
            
            if not char_ids:
                logger.warning(f"    æ— æ³•ä»æ–‡ä»¶åæå–è§’è‰²ID: {mod_dir}")
                return None
            
            # å¦‚æœæœ‰å¤šä¸ªIDï¼Œè¾“å‡ºè­¦å‘Šå¹¶ä½¿ç”¨ç¬¬ä¸€ä¸ª
            if len(char_ids) > 1:
                logger.warning(f"    å‘ç°å¤šä¸ªè§’è‰²ID: {char_ids}ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª: {char_ids[0]}")
            
            return char_ids[0]
            
        except Exception as e:
            logger.error(f"æå–è§’è‰²IDå¤±è´¥ {mod_dir}: {e}")
            return None
    
    def _save_replace_mapping(self, tasks: List[ReplaceTask], filename: str = "æ¸…å•.json") -> None:
        """
        ä¿å­˜æ›¿æ¢æ˜ å°„æ¸…å•åˆ°JSONæ–‡ä»¶
        
        å‚æ•°:
            tasks: æ›¿æ¢ä»»åŠ¡åˆ—è¡¨
            filename: ä¿å­˜çš„æ–‡ä»¶å
        """
        try:
            # è½¬æ¢ä¸ºJSONæ ¼å¼
            json_data = []
            for task in tasks:
                # é€šè¿‡è§’è‰²IDè·å–è§’è‰²å’Œæœè£…ä¿¡æ¯
                char_data = self.character_scraper.get_character_by_id(task.char_id)
                char_name = char_data.character if char_data else task.char_id
                costume_name = char_data.costume if char_data else "æœªçŸ¥"
                
                json_data.append({
                    "char": char_name,
                    "costume": costume_name,
                    "char_id": task.char_id,
                    "type": task.type,
                    "replaceDir": task.replace_dir,
                    "dataName": task.data_name,
                    "downloadedDir": task.downloaded_dir,
                    "targetDir": task.target_dir,
                    "modName": task.mod_name,
                    "shouldExecute": task.should_execute
                })
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            mapping_file = self.project_root / filename
            with open(mapping_file, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, indent=4, ensure_ascii=False)
            
            logger.info(f"æ›¿æ¢æ˜ å°„æ¸…å•å·²ä¿å­˜åˆ°: {mapping_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ›¿æ¢æ˜ å°„æ¸…å•å¤±è´¥: {e}")
    
    def process_updates(self, summary: UpdateSummary) -> Tuple[bool, list[ReplaceTask]]:
        """
        å¤„ç†æ›´æ–°ï¼ˆä¸‹è½½èµ„æºå’Œæ›¿æ¢ï¼‰
        
        å‚æ•°:
            summary: æ›´æ–°æ‘˜è¦
            
        è¿”å›:
            Tuple[bool, List[ReplaceTask]]: (æ˜¯å¦æˆåŠŸå¤„ç†, æ›¿æ¢ä»»åŠ¡åˆ—è¡¨)
        """
        logger.info("å¼€å§‹å¤„ç†æ›´æ–°...")
        
        try:
            # å¦‚æœç‰ˆæœ¬æœ‰å˜åŒ–ï¼Œæ‰§è¡Œå®Œæ•´æ›¿æ¢æµç¨‹
            is_update_dir = False
            if summary.version_changed:
                logger.info("æ£€æµ‹åˆ°ç‰ˆæœ¬æ›´æ–°ï¼Œæ‰§è¡Œå®Œæ•´æ›¿æ¢æµç¨‹...")
                
                # ç¬¬ä¸€æ­¥ï¼šå»ºç«‹æ›¿æ¢æ˜ å°„æ¸…å•
                logger.info("ğŸ” ç¬¬ä¸€æ­¥ï¼šå»ºç«‹æ›¿æ¢æ˜ å°„æ¸…å•")
                replace_tasks = self._build_replace_mapping()
                
                if not replace_tasks:
                    logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ›¿æ¢çš„ä»»åŠ¡")
                    return True,replace_tasks
                
                # ä¿å­˜æ¸…å•åˆ°æ–‡ä»¶
                # self._save_replace_mapping(replace_tasks, "å®Œæ•´æ›¿æ¢æ¸…å•.json")
                
                # è¾“å‡ºæ¸…å•æ‘˜è¦
                logger.info("ğŸ“‹ æ›¿æ¢ä»»åŠ¡æ‘˜è¦:")
                executed_count = 0
                for i, task in enumerate(replace_tasks, 1):
                    status = "âœ… æ‰§è¡Œ" if task.should_execute else "â­ï¸ è·³è¿‡"
                    if task.should_execute:
                        executed_count += 1
                    
                    # é€šè¿‡è§’è‰²IDè·å–è§’è‰²å’Œæœè£…ä¿¡æ¯ç”¨äºæ˜¾ç¤º
                    char_data = self.character_scraper.get_character_by_id(task.char_id)
                    char_name = char_data.character if char_data else task.char_id
                    costume_name = char_data.costume if char_data else "æœªçŸ¥"
                    
                    logger.info(f"  {i}. {status} - {char_name}/{costume_name}/{task.type} (ID: {task.char_id})")
                    logger.info(f"     å€¼: {task.idle_or_cutscene_value}")
                    logger.info(f"     èµ„æº: {task.data_name}")
                    logger.info(f"     Hash: {task.hash_id}")
                    logger.info(f"     MODåç§°: {task.mod_name}")
                    if executed_count == 0:
                        logger.info("âœ… æ²¡æœ‰éœ€è¦æ‰§è¡Œçš„æ›¿æ¢ä»»åŠ¡")
                        return True,replace_tasks
                
                logger.info(f"âœ… å®Œæ•´æ›¿æ¢æ˜ å°„æ¸…å•å»ºç«‹å®Œæˆ (æ‰§è¡Œ: {executed_count}/{len(replace_tasks)})")
                
            elif summary.replace_dirs_to_update:
                is_update_dir = True
                logger.info("æ£€æµ‹åˆ°æ–‡ä»¶æ›´æ–°ï¼Œå¤„ç†å¢é‡æ›¿æ¢...")
                
                # å»ºç«‹å¢é‡æ›¿æ¢æ˜ å°„æ¸…å•
                logger.info("ğŸ” å»ºç«‹å¢é‡æ›¿æ¢æ˜ å°„æ¸…å•")
                replace_tasks = self._build_replace_mapping(summary.replace_dirs_to_update)
                
                if not replace_tasks:
                    logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¢é‡æ›¿æ¢çš„ä»»åŠ¡")
                    return True,replace_tasks
                
                # ä¿å­˜å¢é‡æ¸…å•åˆ°æ–‡ä»¶
                # self._save_replace_mapping(replace_tasks, "å¢é‡æ›¿æ¢æ¸…å•.json")
                
                # è¾“å‡ºå¢é‡æ¸…å•æ‘˜è¦
                logger.info("ğŸ“‹ å¢é‡æ›¿æ¢ä»»åŠ¡æ‘˜è¦:")
                executed_count = 0
                for i, task in enumerate(replace_tasks, 1):
                    status = "âœ… æ‰§è¡Œ" if task.should_execute else "â­ï¸ è·³è¿‡"
                    if task.should_execute:
                        executed_count += 1
                    
                    # é€šè¿‡è§’è‰²IDè·å–è§’è‰²å’Œæœè£…ä¿¡æ¯ç”¨äºæ˜¾ç¤º
                    char_data = self.character_scraper.get_character_by_id(task.char_id)
                    char_name = char_data.character if char_data else task.char_id
                    costume_name = char_data.costume if char_data else "æœªçŸ¥"
                    
                    logger.info(f"  {i}. {status} - {char_name}/{costume_name}/{task.type} (ID: {task.char_id})")
                    logger.info(f"     å€¼: {task.idle_or_cutscene_value}")
                    logger.info(f"     èµ„æº: {task.data_name}")
                    logger.info(f"     Hash: {task.hash_id}")
                    logger.info(f"     MODåç§°: {task.mod_name}")
                if executed_count == 0:
                    logger.info("âœ… æ²¡æœ‰éœ€è¦æ‰§è¡Œçš„æ›¿æ¢ä»»åŠ¡")
                    return True,replace_tasks
                
                logger.info(f"âœ… å¢é‡æ›¿æ¢æ˜ å°„æ¸…å•å»ºç«‹å®Œæˆ (æ‰§è¡Œ: {executed_count}/{len(replace_tasks)})")
                # if executed_count == 0:
                #     logger.info("âœ… æ²¡æœ‰éœ€è¦æ‰§è¡Œçš„å¢é‡æ›¿æ¢ä»»åŠ¡")
                #     return True,replace_tasks

            
            # ç¬¬äºŒæ­¥ï¼šä¸‹è½½èµ„æºæ–‡ä»¶
            logger.info("ğŸ“¥ ç¬¬äºŒæ­¥ï¼šä¸‹è½½èµ„æºæ–‡ä»¶")
            success = self._download_resources(replace_tasks)
            if not success:
                logger.error("èµ„æºä¸‹è½½å¤±è´¥")
                return False,replace_tasks
            
            # ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡ŒUnityèµ„æºæ›¿æ¢
            logger.info("ğŸ”„ ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡ŒUnityèµ„æºæ›¿æ¢")
            success = self._process_unity_resources(replace_tasks, is_update_dir)
            if not success:
                logger.error("Unityèµ„æºæ›¿æ¢å¤±è´¥")
                return False,replace_tasks
            
            # ç¬¬å››æ­¥ï¼šç”ŸæˆREADMEæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰ä»»åŠ¡ä¿¡æ¯ï¼‰
            logger.info("ğŸ“ ç¬¬å››æ­¥ï¼šç”ŸæˆREADMEæ–‡ä»¶")
            self._generate_all_readme_files(replace_tasks)
            
            logger.info("âœ… æ›´æ–°å¤„ç†å®Œæˆ")
            return True,replace_tasks
            
        except Exception as e:
            logger.error(f"å¤„ç†æ›´æ–°å¤±è´¥: {e}")
            return False,replace_tasks
    
    def _download_resources(self, replace_tasks: List[ReplaceTask]) -> bool:
        """
        ä¸‹è½½èµ„æºæ–‡ä»¶
        
        å‚æ•°:
            replace_tasks: æ›¿æ¢ä»»åŠ¡åˆ—è¡¨
            
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸä¸‹è½½
        """
        try:
            # è·å–æ‰€æœ‰éœ€è¦ä¸‹è½½çš„èµ„æºï¼ˆå»é‡ï¼‰ï¼Œåªå¤„ç†éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡
            unique_resources = {}
            executable_tasks = [task for task in replace_tasks if task.should_execute]
            
            for task in executable_tasks:
                if task.data_name not in unique_resources:
                    unique_resources[task.data_name] = task
            
            total_tasks = len(replace_tasks)
            executable_count = len(executable_tasks)
            logger.info(f"æ€»ä»»åŠ¡æ•°: {total_tasks}, éœ€è¦æ‰§è¡Œ: {executable_count}, éœ€è¦ä¸‹è½½ {len(unique_resources)} ä¸ªå”¯ä¸€èµ„æºæ–‡ä»¶")
            
            if not unique_resources:
                logger.info("æ— éœ€ä¸‹è½½ä»»ä½•èµ„æºæ–‡ä»¶")
                return True
            
            # é€ä¸ªä¸‹è½½
            for i, (data_name, task) in enumerate(unique_resources.items(), 1):
                logger.info(f"[{i}/{len(unique_resources)}] ä¸‹è½½: {data_name}")
                
                try:
                    downloaded_path = self.data_downloader.download_data(data_name)
                    logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {downloaded_path}")
                except Exception as e:
                    logger.error(f"âŒ ä¸‹è½½å¤±è´¥ {data_name}: {e}")
                    return False
            
            logger.info("ğŸ‰ æ‰€æœ‰èµ„æºä¸‹è½½å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"ä¸‹è½½èµ„æºå¤±è´¥: {e}")
            return False

    def _process_unity_resources(self, replace_tasks: List[ReplaceTask], is_update_dir: bool) -> bool:
        """
        å¤„ç†Unityèµ„æºæ›¿æ¢
        
        å‚æ•°:
            replace_tasks: æ›¿æ¢ä»»åŠ¡åˆ—è¡¨
            
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸå¤„ç†
        """
        try:
            # æŒ‰ç›®æ ‡ç›®å½•åˆ†ç»„ä»»åŠ¡ï¼Œåªå¤„ç†éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡
            tasks_by_target = {}
            executable_tasks = [task for task in replace_tasks if task.should_execute]
            
            for task in executable_tasks:
                target_dir = task.target_dir
                if target_dir not in tasks_by_target:
                    tasks_by_target[target_dir] = []
                tasks_by_target[target_dir].append(task)
            
            total_tasks = len(replace_tasks)
            executable_count = len(executable_tasks)
            logger.info(f"æ€»ä»»åŠ¡æ•°: {total_tasks}, éœ€è¦æ‰§è¡Œ: {executable_count}, éœ€è¦å¤„ç† {len(tasks_by_target)} ä¸ªç›®æ ‡æ–‡ä»¶")
            
            if not tasks_by_target:
                logger.info("æ— éœ€å¤„ç†ä»»ä½•Unityèµ„æº")
                return True
            
            # é€ä¸ªå¤„ç†ç›®æ ‡æ–‡ä»¶
            for i, (target_dir, group_tasks) in enumerate(tasks_by_target.items(), 1):
                logger.info(f"[{i}/{len(tasks_by_target)}] å¤„ç†ç›®æ ‡: {target_dir}")
                
                # è·å–æºbundleæ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªä»»åŠ¡çš„ä¿¡æ¯ï¼‰
                first_task = group_tasks[0]
                source_bundle_path = str(self.downloaded_dir / first_task.data_name / "__data")
                # æ”¶é›†æ‰€æœ‰æ›¿æ¢ç›®å½•
                replace_dirs = [task.replace_dir for task in group_tasks]
                
                # ç”Ÿæˆç›®æ ‡è·¯å¾„
                target_path = str(self.project_root / target_dir)
                
                try:
                    # ä½¿ç”¨Unityå¤„ç†å™¨çš„å¤šç›®å½•æ›¿æ¢åŠŸèƒ½
                    success = self.unity_processor.process_multiple_replace_dirs(
                        bundle_path=source_bundle_path,
                        replace_dirs=replace_dirs,
                        target_path=target_path
                    )
                    
                    if success:
                        logger.info(f"âœ… å¤„ç†å®Œæˆ: {target_dir}")
                    else:
                        logger.error(f"âŒ å¤„ç†å¤±è´¥: {target_dir}")
                        return False
                        
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†å¤±è´¥ {target_dir}: {e}")
                    return False
            
            logger.info("ğŸ‰ æ‰€æœ‰Unityèµ„æºå¤„ç†å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"å¤„ç†Unityèµ„æºå¤±è´¥: {e}")
            return False
    
    def _generate_all_readme_files(self, replace_tasks: List[ReplaceTask]) -> None:
        """
        ä¸ºæ‰€æœ‰ç›®æ ‡ç›®å½•ç”ŸæˆREADMEæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰ä»»åŠ¡ä¿¡æ¯ï¼Œæ— è®ºæ˜¯å¦æ‰§è¡Œï¼‰
        
        å‚æ•°:
            replace_tasks: æ‰€æœ‰æ›¿æ¢ä»»åŠ¡åˆ—è¡¨
        """
        try:
            # æŒ‰ç›®æ ‡ç›®å½•åˆ†ç»„æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬ä¸æ‰§è¡Œçš„ï¼‰
            tasks_by_target = {}
            for task in replace_tasks:
                target_dir = task.target_dir
                if target_dir not in tasks_by_target:
                    tasks_by_target[target_dir] = []
                tasks_by_target[target_dir].append(task)
            
            logger.info(f"ç”Ÿæˆ {len(tasks_by_target)} ä¸ªREADMEæ–‡ä»¶")
            
            # ä¸ºæ¯ä¸ªç›®æ ‡ç›®å½•ç”ŸæˆREADME
            for target_dir, group_tasks in tasks_by_target.items():
                target_path = str(self.project_root / target_dir)
                self._create_mod_readme(target_path, group_tasks)
            
            logger.info("ğŸ“ æ‰€æœ‰READMEæ–‡ä»¶ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç”ŸæˆREADMEæ–‡ä»¶å¤±è´¥: {e}")
    
    def _create_mod_readme(self, target_path: str, tasks: List[ReplaceTask]) -> None:
        """
        åœ¨ç›®æ ‡ç›®å½•åˆ›å»ºREADMEæ–‡ä»¶
        
        å‚æ•°:
            target_path: ç›®æ ‡è·¯å¾„
            tasks: ç›¸å…³çš„æ›¿æ¢ä»»åŠ¡åˆ—è¡¨
        """
        try:
            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            Path(target_path).parent.mkdir(parents=True, exist_ok=True)
            
            readme_path = Path(target_path).parent / "README.txt"
            
            # ç»Ÿè®¡æ‰§è¡ŒçŠ¶æ€
            executed_tasks = [task for task in tasks if task.should_execute]
            skipped_tasks = [task for task in tasks if not task.should_execute]
            
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write("BD2 MODèµ„æºåŒ…\n")
                f.write("=" * 30 + "\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»MODæ•°é‡: {len(tasks)}\n")
                f.write(f"å·²æ›´æ–°MOD: {len(executed_tasks)}\n")
                f.write(f"æœªæ›´æ”¹MOD: {len(skipped_tasks)}\n\n")

                # å·²æ›´æ–°çš„MOD
                if executed_tasks:
                    f.write("å·²æ›´æ–°çš„MOD:\n")
                    f.write("-" * 20 + "\n")
                    for i, task in enumerate(executed_tasks, 1):
                        # é€šè¿‡è§’è‰²IDè·å–è§’è‰²å’Œæœè£…ä¿¡æ¯ç”¨äºæ˜¾ç¤º
                        char_data = self.character_scraper.get_character_by_id(task.char_id)
                        char_name = char_data.character if char_data else task.char_id
                        costume_name = char_data.costume if char_data else "æœªçŸ¥"
                        
                        f.write(f"{i}. âœ… {task.mod_name}\n")
                        f.write(f"   è§’è‰²ID: {task.char_id}\n")
                        f.write(f"   è§’è‰²: {char_name}\n")
                        f.write(f"   æœè£…: {costume_name}\n")
                        f.write(f"   ç±»å‹: {task.type}\n")
                        f.write(f"   æ›¿æ¢ç›®å½•: {task.replace_dir}\n\n")
                
                # è·³è¿‡çš„MOD
                if skipped_tasks:
                    f.write("æœªæ›´æ”¹çš„MOD:\n")
                    f.write("-" * 20 + "\n")
                    for i, task in enumerate(skipped_tasks, 1):
                        # é€šè¿‡è§’è‰²IDè·å–è§’è‰²å’Œæœè£…ä¿¡æ¯ç”¨äºæ˜¾ç¤º
                        char_data = self.character_scraper.get_character_by_id(task.char_id)
                        char_name = char_data.character if char_data else task.char_id
                        costume_name = char_data.costume if char_data else "æœªçŸ¥"
                        
                        f.write(f"{i}. â­ï¸ {task.mod_name}\n")
                        f.write(f"   è§’è‰²ID: {task.char_id}\n")
                        f.write(f"   è§’è‰²: {char_name}\n")
                        f.write(f"   æœè£…: {costume_name}\n")
                        f.write(f"   ç±»å‹: {task.type}\n")
                        f.write(f"   æ›¿æ¢ç›®å½•: {task.replace_dir}\n")
                        f.write(f"   åŸå› : ç›®å½•æœªåœ¨æ›´æ–°åˆ—è¡¨ä¸­\n\n")
                
                f.write("ä½¿ç”¨è¯´æ˜:\n")
                f.write("1. å°†__dataæ–‡ä»¶å¤åˆ¶åˆ°æ¸¸æˆå¯¹åº”ä½ç½®\n")
                f.write("2. ç¡®ä¿æ–‡ä»¶è·¯å¾„ç»“æ„æ­£ç¡®\n")
                f.write("3. é‡æ–°å¯åŠ¨æ¸¸æˆä»¥åº”ç”¨ä¿®æ”¹\n")
                f.write("4. è·³è¿‡çš„MODéœ€è¦æ‰‹åŠ¨è§¦å‘æ›´æ–°æ‰ä¼šåº”ç”¨\n\n")
                
                f.write("ç›®å½•ç»“æ„è¯´æ˜:\n")
                f.write("æ–°çš„ç®€åŒ–ç›®å½•ç»“æ„: ä½œè€…å/IDLEæˆ–CUTSCENE/MODåç§°/\n")
                f.write("â€¢ MODæ–‡ä»¶å‘½åå¿…é¡»åŒ…å«è§’è‰²ID (å¦‚: char000101.atlas)\n")
                f.write("â€¢ ç³»ç»Ÿä¼šä»æ–‡ä»¶åè‡ªåŠ¨è¯†åˆ«è§’è‰²å’Œæœè£…ä¿¡æ¯\n")
                f.write("â€¢ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .atlas, .modfile, .skel, .json\n")
                f.write("â€¢ æ”¯æŒçš„è§’è‰²IDæ ¼å¼: char*, illust_*, specialIllust*ç­‰\n")
            
            logger.info(f"ğŸ“ å·²ç”ŸæˆREADMEæ–‡ä»¶: {readme_path}")
            
        except Exception as e:
            logger.warning(f"åˆ›å»ºREADMEæ–‡ä»¶å¤±è´¥: {e}")
    
    def run(self) -> bool:
        """
        è¿è¡Œä¸»æµç¨‹
        
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸæ‰§è¡Œ
        """
        try:
            logger.info("ğŸ® BD2èµ„æºæ›¿æ¢å·¥å…·å¯åŠ¨")
            logger.info("=" * 50)
            
            # æ£€æµ‹ç‰ˆæœ¬å’Œæ›´æ–°
            needs_update, summary = self.check_version_and_updates()
            
            # è¾“å‡ºæ£€æµ‹ç»“æœ
            logger.info("ğŸ“Š æ£€æµ‹ç»“æœæ‘˜è¦:")
            logger.info(f"  ç‰ˆæœ¬å˜åŒ–: {summary.version_changed}")
            if summary.old_version is not None and summary.new_version is not None:
                logger.info(f"  ç‰ˆæœ¬: {summary.old_version} -> {summary.new_version}")
            logger.info(f"  æ€»æ›¿æ¢ç›®å½•æ•°: {summary.total_replace_dirs}")
            logger.info(f"  éœ€è¦æ›´æ–°çš„ç›®å½•æ•°: {len(summary.replace_dirs_to_update)}")
            
            if not needs_update:
                logger.info("âœ… æ— éœ€æ›´æ–°ï¼Œç¨‹åºé€€å‡º")
                return True
            
            logger.info("ğŸ”„ æ£€æµ‹åˆ°æ›´æ–°ï¼Œå¼€å§‹å¤„ç†...")
            
            # å¤„ç†æ›´æ–°
            success = self.process_updates(summary)
            
            if success:
                logger.info("âœ… æ›´æ–°å¤„ç†å®Œæˆ")
            else:
                logger.error("âŒ æ›´æ–°å¤„ç†å¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"ä¸»æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    try:
        manager = BD2ResourceManager()
        success = manager.run()
        return 0 if success else 1
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        return 1
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())
